$$E[X]=\sum_{s \in S}s\cdot Pr[X=s]$$
Expectation is linear:
$$E[\Sigma_i X_i]=\sum_i E[X_i]$$
for any set of $X_i$'s.

If $X_1$ and $X_2$ are independent, then:
$$E[X_1 \cdot X_2]=E[X_1]\cdot E[X_2]$$
##### Variance
The variance of X is denoted $Var[X]$ and it measures how much $X$ deviates from its expected value.
$$Var[X]=E[(X-E[X])^2]=E[X^2]-E[X]^2$$
Related: [[Chebyshev's Inequality]]